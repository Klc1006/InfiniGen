{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:01:41", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": 4, "max_beam_len": 8, "top_p": 0.9, "max_new_tokens": 32, "max_budget": 16, "max_branch_width": 32, "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:04:13", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": 4, "max_beam_len": 8, "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": 32, "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:05:26", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": 4, "max_beam_len": 8, "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": 32, "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:27:21", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:29:28", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:38:11", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:39:46", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 17:43:44", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-26 21:02:26", "date": "251126", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/opt-6.7b", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-27 16:48:28", "date": "251127", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/opt-6.7b", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-27 16:50:39", "date": "251127", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/opt-6.7b", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "8", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-27 16:51:36", "date": "251127", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
{"msg_type": "config", "gen_type": "specexecbeams", "model_0": "/mnt/data/clk/TinyLlama-1.1B-Chat-v1.0", "model_1": "/mnt/data/clk/opt-6.7b", "temperature": 0.6, "max_n_beams": "4", "max_beam_len": "4", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 10, "seed": 0, "dataset": "oasst", "timestamp": "2025-11-27 17:06:33", "date": "251127", "hostname": "TitanTwins", "commit": "none", "offload": false, "device": "GeForce RTX 4090"}
